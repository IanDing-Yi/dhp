{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.distributions as distributions\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hist_dataloader import tiny_Dataset, Rescale, ToTensor\n",
    "from pretrain_model import get_pretrain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, optimizer, trainloader, criterion, disp):\n",
    "    count = 0\n",
    "    policy_losses = []\n",
    "    value_losses = []\n",
    "    episode_reward = []\n",
    "    if(disp):\n",
    "        print(device)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        count += 1\n",
    "        if device is None:\n",
    "            inputs = data[0].type(torch.FloatTensor)\n",
    "            labels = data[1].type(torch.FloatTensor)\n",
    "        else:\n",
    "            inputs = data[0].type(torch.FloatTensor).to(device)\n",
    "            labels = data[1].type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        value_pred = clf(inputs)\n",
    "        value_loss = criterion(value_pred.float(), labels).sum()\n",
    "        \n",
    "#         if(disp):\n",
    "#             print(value_loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        value_losses.append(float(value_loss.item()))\n",
    "\n",
    "    return sum(value_losses)/len(value_losses)\n",
    "\n",
    "\n",
    "# evaluation\n",
    "def comp_test(stage, clf, testloader, criterion, disp):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    preds = np.empty(0)\n",
    "    lbs = np.empty(0)\n",
    "    loss = []\n",
    "    if(disp):\n",
    "        print(device)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            if device is None:\n",
    "                inputs = data[0]\n",
    "                labels = data[1]\n",
    "            else:\n",
    "                inputs = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "\n",
    "            outputs = clf(inputs)\n",
    "            val_loss = criterion(outputs.float(), labels).sum()\n",
    "            loss.append(val_loss)\n",
    "#             predicted = torch.round(torch.sigmoid(outputs))\n",
    "            predicted = torch.argmax(torch.softmax(outputs, dim=-1), dim=-1)\n",
    "            pred_npy = predicted.detach().cpu().numpy()\n",
    "            total += labels.size(0)\n",
    "            labels = torch.argmax(torch.softmax(labels, dim=-1), dim=-1)\n",
    "            lb_npy = labels.detach().cpu().numpy()\n",
    "            correct += (pred_npy == lb_npy).sum().item()\n",
    "            preds = np.hstack((preds, pred_npy.squeeze()))\n",
    "            lbs = np.hstack((lbs, lb_npy.squeeze()))\n",
    "\n",
    "    conmx = confusion_matrix(lbs, preds)\n",
    "    if(disp):\n",
    "        print(stage+' accuracy: %.6f %%' % (100 * correct / total))\n",
    "#     tn, fp, fn, tp = conmx.ravel()\n",
    "#     if (tp + fp) == 0:\n",
    "#         prec = 0\n",
    "#     else:\n",
    "#         prec = tp / (tp + fp)\n",
    "#     if (tp + fn) == 0:\n",
    "#         recl = 0\n",
    "#     else:\n",
    "#         recl = tp / (tp + fn)\n",
    "#     if (prec+recl) == 0:\n",
    "#         f1 = 0\n",
    "#     else:\n",
    "#         f1 = (2*prec*recl) / (prec+recl)\n",
    "#     if(disp):\n",
    "#         print('Precision:', prec)\n",
    "#         print('Recall:', recl)\n",
    "#         print('F1:', f1)\n",
    "    return (correct / total), conmx, sum(loss)/len(loss)\n",
    "\n",
    "def run_train(train_csv, val_csv, root_folder, save_path, disp):\n",
    "    start_time = time.time()\n",
    "\n",
    "    test_csv = val_csv\n",
    "\n",
    "    train_dataset = tiny_Dataset(csv_file=train_csv,\n",
    "                                 root_dir=root_folder,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     Rescale((224,224)),\n",
    "                                     ToTensor()\n",
    "                                 ]))\n",
    "    test_dataset = tiny_Dataset(csv_file=test_csv,\n",
    "                                root_dir=root_folder,\n",
    "                                transform=transforms.Compose([\n",
    "                                    Rescale((224,224)),\n",
    "                                    ToTensor()\n",
    "                                ]))\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, num_workers=0)\n",
    "\n",
    "    clf = get_pretrain_model('alexnet')\n",
    "    clf.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer_clf = optim.Adam(clf.parameters(), lr=0.0001)\n",
    "\n",
    "    max_test_perf = 10000\n",
    "    min_delta = 0\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "\n",
    "    MAX_EPISODES = 1000\n",
    "    PRINT_EVERY = 1\n",
    "\n",
    "    records = {'train': [],'valid': []}\n",
    "    for episode in range(1, MAX_EPISODES+1):  # loop over the dataset multiple times\n",
    "        if(disp):\n",
    "            print('episode:', episode)\n",
    "        critic_loss = train(clf, optimizer_clf, trainloader, criterion, disp)\n",
    "        if(disp):\n",
    "            print('Train')\n",
    "        tr_cur_acc, tr_conmx, tr_loss = comp_test('Train', clf, trainloader, criterion, disp)\n",
    "        records['train'].append([tr_cur_acc, tr_conmx, tr_loss])\n",
    "        if(disp):\n",
    "            print('train loss: ', critic_loss)\n",
    "            print('train loss: ', tr_loss)\n",
    "            print('Validation')\n",
    "        cur_acc, conmx, val_loss = comp_test('Validation', clf, testloader, criterion, disp)\n",
    "        records['valid'].append([cur_acc, conmx, val_loss])\n",
    "        \n",
    "        if(disp):\n",
    "            print('validation loss: ', val_loss)\n",
    "\n",
    "        if max_test_perf - val_loss > min_delta:\n",
    "            if(disp):\n",
    "                print('refresh patience')\n",
    "            max_test_perf = val_loss\n",
    "            counter = 0\n",
    "            # save model\n",
    "            cur_high = [cur_acc, conmx]\n",
    "            torch.save(clf.state_dict(), save_path)\n",
    "    #                 print('after  val_loss', val_loss, 'best_loss', best_loss)\n",
    "        elif max_test_perf - val_loss < min_delta:\n",
    "#             if (episode > 50):\n",
    "            if(disp):\n",
    "                print('patience counter +1')\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "\n",
    "    # print('\\t'.join([str(it) for it in [cur_high[3], cur_high[0], cur_high[1], cur_high[2]]]))\n",
    "\n",
    "\n",
    "    if(disp):\n",
    "        print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "    if(disp):\n",
    "        print(time_elapsed)\n",
    "\n",
    "    return records\n",
    "\n",
    "def run_test(test_csv, root_folder, model_path, disp):\n",
    "    # run test\n",
    "    start_time = time.time()\n",
    "\n",
    "    pth = model_path\n",
    "    \n",
    "    test_dataset = tiny_Dataset(csv_file=test_csv,\n",
    "                                root_dir=root_folder,\n",
    "                                transform=transforms.Compose([\n",
    "                                    Rescale((224,224)),\n",
    "                                    ToTensor()\n",
    "                                ]))\n",
    "    testloader = torch.utils.data.DataLoader(aida17k_test_dataset, batch_size=10, num_workers=0)\n",
    "    \n",
    "    clf = get_pretrain_model('alexnet')\n",
    "    clf.load_state_dict(torch.load(pth))\n",
    "    clf.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    cur_acc, conmx, val_loss = comp_test('Test', clf, testloader, criterion, disp)\n",
    "\n",
    "    if(disp):\n",
    "        print('Finished Testing')\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "    if(disp):\n",
    "        print(time_elapsed)\n",
    "    \n",
    "    return cur_acc, conmx, val_loss\n",
    "\n",
    "def run(var_save_name, run_count = 1, disp = False):\n",
    "    \n",
    "    exps_rslts = []\n",
    "    for iter_count in range(run_count):\n",
    "        #baseline\n",
    "        train_records = run_train('balanced_train.csv',\n",
    "                                  'balanced_valid.csv',\n",
    "                                  '../../dhp_data/artifact_restore_identify/LPW_cistern_collection_photos',\n",
    "                                  'balance_5_20p_alex',\n",
    "                                  disp\n",
    "                                  )\n",
    "        print('balanced', 'train')\n",
    "        cur_acc, conmx, val_loss = run_test('balanced_test.csv',\n",
    "                                           '../../dhp_data/artifact_restore_identify/LPW_cistern_collection_photos',\n",
    "                                           'balance_5_20p_alex',\n",
    "                                           disp\n",
    "                                           )\n",
    "        print('balanced', 'test')\n",
    "        exps_rslts.append([cur_acc, conmx, val_loss, train_records])\n",
    "        print(cur_acc)\n",
    "        display(conmx)\n",
    "\n",
    "        with open('result_data_'+var_save_name+'_'+str(iter_count)+'.pkl', 'wb') as fp:\n",
    "            pickle.dump(exps_rslts, fp)\n",
    "            print('exps rslts saved successfully to file: ', iter_count)\n",
    "        \n",
    "#         print(var_save_name, iter_count)\n",
    "#         print(exps_rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1\n",
      "cuda:0\n",
      "Train\n",
      "cuda:0\n",
      "Train accuracy: 40.000000 %\n",
      "train loss:  0.5510819628834724\n",
      "train loss:  tensor(0.3131, device='cuda:0')\n",
      "Validation\n",
      "cuda:0\n",
      "Validation accuracy: 32.812500 %\n",
      "validation loss:  tensor(0.3375, device='cuda:0')\n",
      "refresh patience\n",
      "episode: 2\n",
      "cuda:0\n",
      "Train\n",
      "cuda:0\n",
      "Train accuracy: 75.000000 %\n",
      "train loss:  0.3077452778816223\n",
      "train loss:  tensor(0.2319, device='cuda:0')\n",
      "Validation\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "run('balanced_train_5_val_20p', 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchgpu]",
   "language": "python",
   "name": "conda-env-torchgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
